{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Experiment for DNN Architecture Sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "N_{est}=\\sum_{i=0}^{L-1} H_{i+1}(H_i + 1) \\text{ where } L \\in \\mathbb{Z}^{++}, H_i \\in \\mathbb{Z}^{++}\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\text{The value of }H_0\\text{ and }H_L\\text{ are known. Find the n combinations of }H_i\\text{ for which all }  {i=0} \\text{ to } {i={L-1}} \\\\ \\text{eg. }(H_0, H_1, H_2, ..., H_L) \\text{ } \\text{where }N_{est}\\text{ is closest to a given integer }N_T.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "from random import uniform\n",
    "from gekko import GEKKO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture Parameters\n",
    "L = 5\n",
    "N_T = 1500\n",
    "H_0 = 5\n",
    "H_L = 1\n",
    "\n",
    "# Sampling Constraints\n",
    "H_min = 1\n",
    "H_max = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_params(H):\n",
    "    N_est = 0\n",
    "    for i in range(len(H)-1):\n",
    "        N_est += H[i+1] * (H[i] + 1)\n",
    "    return(N_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GEKKO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = [H_0]\n",
    "for i in range(1,L-1):\n",
    "    H.append(model.Var(value=round(uniform(H_min,H_max)), integer=True, lb=H_min, ub=H_max))\n",
    "H.append(H_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Minimize(abs(N_T - n_params(H)))\n",
    "model.options.SOLVER = 1\n",
    "model.solver_options = ['minlp_maximum_iterations 10000',\n",
    "                        'minlp_branch_method 3',\n",
    "                        'minlp_max_iter_with_int_sol 500']\n",
    "model.solve(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 36, 21, 22, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = np.hstack(H).astype(int).tolist()\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_params(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_num_params(H):\n",
    "    '''\n",
    "    Compute the total number of parameters in a fully connected neural network\n",
    "    \n",
    "    Args:\n",
    "        H: List of neurons at each layer\n",
    "\n",
    "    Returns:\n",
    "        N: Number of parameters in the fully connected network\n",
    "        \n",
    "    Raises:\n",
    "        -\n",
    "        \n",
    "    Example:\n",
    "        >>> fc_num_params([5, 85, 7, 43, 1])\n",
    "        1500\n",
    "        \n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "\n",
    "    N = 0\n",
    "    for i in range(len(H)-1):\n",
    "        N += H[i+1] * (H[i] + 1)\n",
    "    return(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_sampling(num_params,\n",
    "                        num_layers,\n",
    "                        in_dim,\n",
    "                        out_dim=1, \n",
    "                        n_min=1, \n",
    "                        n_max=None, \n",
    "                        n_samples=1, \n",
    "                        include_inout=True,\n",
    "                        single_sample=False,\n",
    "                        max_trials=1000):\n",
    "    '''\n",
    "    Randomly sampling DNN architecture based on give number of total parameters.\n",
    "    This is use for neuron architecture sampling based on the same number of parameters given.\n",
    "    \n",
    "    Args:\n",
    "        num_params: Total number of parameters to be distributed\n",
    "        num_layers: Total number of layers\n",
    "        n_min:      Minimum number of neurons per layer\n",
    "        n_max:      Maximum number of neurons per layer\n",
    "        in_dim:     Number of neurons at the input layer\n",
    "        out_dim:    Number of neurons at the output layer\n",
    "        n_samples:  Number of architecture samples to return (maximum number of samples return if there are less than demanded)\n",
    "        include_inout: Flag indicate whether to include input and output layer neurons with samples\n",
    "        max_trials: Maximum number of randomized trial for solution sampling if not enough samples found\n",
    "\n",
    "    Returns:\n",
    "        sample: List of elements splitted into multiple dimensions\n",
    "        \n",
    "    Raises:\n",
    "        -\n",
    "        \n",
    "    Example:\n",
    "        >>> parameters_sampling(num_params=500, \n",
    "                                num_layers=5,\n",
    "                                in_dim=5,\n",
    "                                out_dim=1, \n",
    "                                n_min=1, \n",
    "                                n_max=None, \n",
    "                                n_samples=10, \n",
    "                                include_inout=True,\n",
    "                                single_sample=False,\n",
    "                                max_trials=1000)\n",
    "        [[5, 5, 11, 31, 1],\n",
    "         [5, 6, 7, 46, 1],\n",
    "         [5, 18, 9, 20, 1],\n",
    "         [5, 19, 3, 65, 1],\n",
    "         [5, 29, 5, 25, 1],\n",
    "         [5, 29, 9, 5, 1],\n",
    "         [5, 33, 7, 7, 1],\n",
    "         [5, 49, 3, 11, 1],\n",
    "         [5, 54, 1, 40, 1],\n",
    "         [5, 63, 1, 19, 1]]\n",
    "        \n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    \n",
    "    samples = np.empty([0,num_layers],dtype=int)\n",
    "    \n",
    "    for trial in range(max_trials):\n",
    "        # initialize MINLP (Mixed-Integer Nonlinear Programming Model)\n",
    "        model = GEKKO()\n",
    "\n",
    "        # Setup variables to be optimized\n",
    "        H = [in_dim]\n",
    "        for i in range(1,num_layers-1):\n",
    "            # Randomize initial variables for diverse samples\n",
    "            H.append(model.Var(value=round(uniform(H_min,H_max)), integer=True, lb=H_min, ub=H_max))\n",
    "        H.append(out_dim)\n",
    "\n",
    "        # Solving for Optimal Values\n",
    "        model.Minimize(abs(num_params - n_params(H)))\n",
    "        model.options.SOLVER = 1\n",
    "        model.solver_options = ['minlp_maximum_iterations 10000',\n",
    "                                'minlp_branch_method 3',\n",
    "                                'minlp_max_iter_with_int_sol 500']\n",
    "        model.solve(disp=False)\n",
    "        \n",
    "        # Check to make sure new sample is unique and aggregate it for output\n",
    "        H = np.hstack(H).astype(int)\n",
    "        H = H if include_inout else H[1:-1]\n",
    "        samples = np.unique(np.vstack((samples, H)), axis=0)\n",
    "\n",
    "        # Break the loop if we have enough samples\n",
    "        if samples.shape[0] == n_samples:\n",
    "            break\n",
    "\n",
    "    # Convert from Numpy Array back to List\n",
    "    samples = samples.tolist()\n",
    "            \n",
    "    return(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = parameters_sampling(num_params=500, \n",
    "                           num_layers=5,\n",
    "                           in_dim=5,\n",
    "                           out_dim=1, \n",
    "                           n_min=1, \n",
    "                           n_max=None, \n",
    "                           n_samples=10, \n",
    "                           include_inout=True,\n",
    "                           single_sample=False,\n",
    "                           max_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 1, 5, 69, 1],\n",
       " [5, 6, 7, 46, 1],\n",
       " [5, 9, 13, 21, 1],\n",
       " [5, 19, 15, 5, 1],\n",
       " [5, 33, 7, 7, 1],\n",
       " [5, 43, 5, 3, 1],\n",
       " [5, 49, 3, 11, 1],\n",
       " [5, 54, 1, 40, 1],\n",
       " [5, 54, 3, 2, 1],\n",
       " [5, 69, 1, 5, 1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://apmonitor.com/wiki/index.php/Main/IntegerBinaryVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x1,x2):\n",
    "    return(4*x1**2-4*x2*x1**2+x2**2+x1**2-x1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apm 35.157.216.221_gk_model11 <br><pre> ----------------------------------------------------------------\n",
      " APMonitor, Version 1.0.1\n",
      " APMonitor Optimization Suite\n",
      " ----------------------------------------------------------------\n",
      " \n",
      " \n",
      " Warning: there is insufficient data in CSV file 35.157.216.221_gk_model11.csv\n",
      " \n",
      " --------- APM Model Size ------------\n",
      " Each time step contains\n",
      "   Objects      :            0\n",
      "   Constants    :            0\n",
      "   Variables    :            2\n",
      "   Intermediates:            0\n",
      "   Connections  :            0\n",
      "   Equations    :            1\n",
      "   Residuals    :            1\n",
      " \n",
      " Number of state variables:              2\n",
      " Number of total equations: -            0\n",
      " Number of slack variables: -            0\n",
      " ---------------------------------------\n",
      " Degrees of freedom       :              2\n",
      " \n",
      " ----------------------------------------------\n",
      " Steady State Optimization with APOPT Solver\n",
      " ----------------------------------------------\n",
      "Iter:     1 I:  0 Tm:      0.00 NLPi:    5 Dpth:    0 Lvs:    3 Obj:  9.50E-01 Gap:       NaN\n",
      "--Integer Solution:   1.00E+00 Lowest Leaf:   9.50E-01 Gap:   5.04E-02\n",
      "Iter:     2 I:  0 Tm:      0.00 NLPi:    1 Dpth:    1 Lvs:    2 Obj:  1.00E+00 Gap:  5.04E-02\n",
      "--Integer Solution:  -3.05E+02 Lowest Leaf:  -3.05E+02 Gap:   0.00E+00\n",
      "Iter:     3 I:  0 Tm:      0.00 NLPi:    5 Dpth:    1 Lvs:    2 Obj: -3.05E+02 Gap:  0.00E+00\n",
      " Successful solution\n",
      " \n",
      " ---------------------------------------------------\n",
      " Solver         :  APOPT (v1.0)\n",
      " Solution time  :   3.479999999399297E-002 sec\n",
      " Objective      :   -305.000000000000     \n",
      " Successful solution\n",
      " ---------------------------------------------------\n",
      " \n",
      "x1: 10.0\n",
      "x2: 2.0\n"
     ]
    }
   ],
   "source": [
    "from gekko import GEKKO\n",
    "m = GEKKO() # create GEKKO model\n",
    "# create integer variables\n",
    "x1 = m.Var(integer=True,lb=-5,ub=10)\n",
    "x2 = m.Var(integer=True,lb=-1,ub=2)\n",
    "m.Minimize(f(x1,x2))\n",
    "m.options.SOLVER = 1 # APOPT solver\n",
    "m.solve()\n",
    "print('x1: ' + str(x1.value[0]))\n",
    "print('x2: ' + str(x2.value[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://apmonitor.com/wiki/index.php/Main/OptionApmSolver"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p39]",
   "language": "python",
   "name": "conda-env-pytorch_p39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calvin's Scalable Deep Neural Network\n",
    "\n",
    "Written by Calvin W.Y. Chan calvin.chan@bayer.com, June 2021 (Github: https://github.com/calvinwy, Linkedin: https://www.linkedin.com/in/calchan/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from siuba import _, select, rename, left_join\n",
    "from pytorch_forecasting.metrics import MAPE\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "from ray.tune.suggest.basic_variant import BasicVariantGenerator\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from ray.tune.suggest.bohb import TuneBOHB\n",
    "\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import warnings\n",
    "import filelock\n",
    "\n",
    "import string\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=9, micro=5, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake Data Creation Parameters\n",
    "N_SAMPLE = 5000\n",
    "N_FEATURE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling Parameters\n",
    "test_split_ratio = 0.2\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning Algorithm Parameters\n",
    "lr_min = 1e-4\n",
    "lr_max = 1e-1\n",
    "# batch_size = [1,16,32,64]\n",
    "batch_size = [64]\n",
    "\n",
    "# Architecture Sampling Parameters\n",
    "h_total_min = 8\n",
    "h_total_max = 11\n",
    "h_total_step = 2\n",
    "\n",
    "h_min_neuron_per_layer = 2\n",
    "h_max_neuron_per_layer = 5\n",
    "h_max_layer = None\n",
    "\n",
    "dropout_p_min = 0\n",
    "dropout_p_max = 0.7\n",
    "\n",
    "# Only use for Architecture Table Search\n",
    "h_branch_n_samples = 2\n",
    "\n",
    "# Ray Tune Hyperparameter Search\n",
    "num_hp_search_samples = 1\n",
    "chkpt_dir = \"/home/calvin_chan/data/output/checkpoint/testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directories\n",
    "if not os.path.exists(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_colname = [ 'feature_' + x for x in string.ascii_lowercase[:N_FEATURE] ]\n",
    "\n",
    "sample_features = pd.DataFrame(np.random.randn(N_SAMPLE,N_FEATURE),columns=features_colname)\n",
    "y_out = pd.DataFrame(np.random.randint(1000,80000,size=N_SAMPLE).astype(np.double),columns=['y_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_features\n",
    "y = y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7824.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79209.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_out\n",
       "0   7824.0\n",
       "1  32569.0\n",
       "2  66965.0\n",
       "3  17769.0\n",
       "4  79209.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dnn(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, in_feat, layers, dropout_p=None, act_fn=torch.relu):\n",
    "        super(dnn, self).__init__()\n",
    "        layers = [in_feat] + layers   # Add input layer\n",
    "        self.hidden = nn.ModuleList()\n",
    "        self.out = nn.Linear(layers[-1],1).double()\n",
    "        self.act_fn = act_fn\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        # --- Scalable Layers ---\n",
    "        for input_size, output_size in zip(layers, layers[1:]):\n",
    "            self.hidden.append(nn.Linear(input_size,output_size).double())\n",
    "            \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        L = len(self.hidden)\n",
    "        for (l, single_layer) in zip(range(L), self.hidden):\n",
    "            x = single_layer(x)\n",
    "            x = self.dropout(self.act_fn(x))\n",
    "        x = self.act_fn(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling and Hyperparameter Tunning\n",
    "\n",
    "### Overview\n",
    "\n",
    "* Modeling = Train + Validation 80%, Test 20% Data Split\n",
    "* Modeling = Train + Validation 80%, Using K-Fold for Hyperparameters Tunning\n",
    "\n",
    "<ol>\n",
    "    <li>Split the data into 80/20</li>\n",
    "    <li>Use K-Fold cross-validation splitting given k (eg. k=5 would results 80%/5=16% of each fold)</li>\n",
    "    <ol>\n",
    "        <li>For each fold, use the K-Fold training set for building model for each hyperparameters set</li>\n",
    "        <li>For each fold, evaluate all models with different hyperparameters with the K-Fold test set</li>\n",
    "        <li>Summarize the results into a table of (hyperparameter index, K-Fold index)</li>\n",
    "        <li>Find the best hyperparameter set\n",
    "    </ol>\n",
    "    <li>Use the entire \"Modeling = Train + Validation 80%\" dataset to train a model</li>\n",
    "    <li>Evaluate the model using the 20% Test Data\n",
    "</ol>\n",
    "\n",
    "<center>\n",
    "    <img src=\"./graphics/DataHandling.jpg\" width=\"1074\" alt=\"data_splitting\"  />\n",
    "</center>\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Data Splitting\n",
    "* Using `sklearn.model_selection.train_test_split` function to perform the 80/20 split\n",
    "* Generate index for K-fold of the 80% train+validation dataset using `sklearn.model_selection.KFold`\n",
    "* Create a list of pytorch dataloader for each of the K-fold for training\n",
    "* Create a list of pytorch dataloader for each of the K-fold for validation\n",
    "\n",
    "Hyperparameter Tunning\n",
    "* Use K in K-Fold as grid (must run) hyperparameter\n",
    "* Use __custom sampling function__ to describe the hierachical neuron distribution between:\n",
    " * total neuron: $H_{total}$\n",
    " * neuron per layer: $H_{branch}$\n",
    "\n",
    "<p style=\"margin-left: 100px\">$H_{total}=15\\quad\\longrightarrow\\quad H_{branch}=\\begin{bmatrix}[3,3,4,5] \\end{bmatrix}$ </p>\n",
    "    \n",
    "* __Custom Sampling Function__\n",
    " * Using the total number of neuron from the last level, create all possible combination given the number of element\n",
    " * Sample an element from the list of combination and returns it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling-Testing 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_multidimensional_labels(df,col):\n",
    "    '''\n",
    "    Convert Multiple Column Label into Single Column\n",
    "    \n",
    "    Args:\n",
    "        df: A pandas dataframe with row as samples, and column as N-dimensional subgroup to be encoded.\n",
    "        col: Column name of the combined column\n",
    "        \n",
    "    Returns:\n",
    "        df: A pandas dataframe with new label column\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    if df.shape[1] == 1:\n",
    "        df = pd.concat([df,df],axis=1)\n",
    "        df.columns = [df.columns[0],col]\n",
    "    else:\n",
    "        df[col] = tuple(labels.values.tolist())\n",
    "        df[col] = labels[col].apply(lambda x: ','.join([str(c) for c in x ]))\n",
    "    return(df)\n",
    "\n",
    "def combine_multidimensional_ohe(s):\n",
    "    '''\n",
    "    One-Hot-Encoding (OHE) based on joint label of multiple columns\n",
    "    The default OHE feature of Pandas and sklearn takes each column as independent OHE. \n",
    "    This function uses the 2D unique label combination as a single dimension for OHE.\n",
    "    \n",
    "    Args:\n",
    "        s: A pandas dataframe with row as samples, and column as N-dimensional subgroup to be encoded.\n",
    "\n",
    "    Returns:\n",
    "        s_ohe: A pandas dataframe with N-D OHE\n",
    "        conversion_table: The conversion table for N-D OHE\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    unique_labels = [ sorted(s[name].unique().tolist()) for name in s.columns.tolist() ]\n",
    "    multidimensional_labels = [*itertools.product(*unique_labels)]\n",
    "    labels = pd.DataFrame(multidimensional_labels, columns=s.columns.tolist())\n",
    "    labels = convert_multidimensional_labels(labels,'sgrp')\n",
    "    conversion_table = pd.get_dummies(labels, columns=['sgrp'])\n",
    "    s_ohe = pd.merge(s,conversion_table,on=s.columns.tolist(),how='left').drop(s.columns.tolist(),axis=1)\n",
    "    return(s_ohe,conversion_table)\n",
    "\n",
    "\n",
    "def unique_list(ls_of_ls):\n",
    "    '''\n",
    "    Return the unique list in a list of list\n",
    "    \n",
    "    Args:\n",
    "        ls_of_ls: List of list (eg. [[1,2,3],[1,3,2],[1,2,3]])\n",
    "\n",
    "    Returns:\n",
    "        unique_ls: Unique list within the input list (eg. [[1,3,2],[1,2,3]])\n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    unique_ls = [list(ls_out) for ls_out in set(tuple(ls) for ls in ls_of_ls)]\n",
    "    return unique_ls\n",
    "\n",
    "\n",
    "def model_test_split(*args, id_col=None, test_ratio=0.2, random_state=25, report_id=False):\n",
    "    \n",
    "    '''\n",
    "    Split the dataset into modeling and test set\n",
    "    \n",
    "    This function is to encapsulate the variying input feature size given the grouping by id_col,\n",
    "    and this decompose the one-hot-encoding column into a separate feature set to be used in the\n",
    "    deep learning model as separate input.\n",
    "    \n",
    "    Args:\n",
    "        *args:\n",
    "            x: A pandas dataframe with row as samples, and column as ID and feature type\n",
    "            y: A pandas dataframe with row as samples, and column as output\n",
    "        ohe_col: A list of column names indicating the one-hot-encoding columns in x\n",
    "        id_col: Column name of the grouping column to be converted to one-hot-encoding\n",
    "        test_size: The split ratio of the test set\n",
    "        random_state: Random seed use by the `sklearn.model_selection.train_test_split` function\n",
    "        retain_df: If this is 'True' and the input 'args' are dataframes, do not convert them to list of single row dataframe\n",
    "\n",
    "    Returns:\n",
    "        x_model, x_test: List of numpy matrix as model/test data split with from commond id_col labels of x and y\n",
    "        s_model, s_test: List of numpy matrix as model/test data split with from commond id_col labels of x and y\n",
    "        y_model, y_test: List of numpy matrix as model/test data split with from commond id_col labels of x and y\n",
    "\n",
    "    Raises:\n",
    "        Warning when the labels in id_col of x and y do not match\n",
    "        \n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "\n",
    "    if id_col is not None:\n",
    "\n",
    "        inds = []\n",
    "        data = []\n",
    "        for arg in args:\n",
    "            (ind,dat) = zip(*list(arg.groupby(id_col)))\n",
    "            inds.append(ind)\n",
    "            data.append(dat)\n",
    "\n",
    "        # Determine of ID entry is missing from any of the input dataset\n",
    "        id_not_match_flag = !(len(set.intersection(*[set(ind) for ind in inds])) == len(set.union(*[set(ind) for ind in inds])))\n",
    "        if not id_not_match_flag:\n",
    "            warnings.warn(\"Unmatch ID entries in one or more data inputs (eg. x, y)!\")\n",
    "\n",
    "        # Extract Common ID from x, s, y Samples\n",
    "        select_ids = list(set.intersection(*[set(ind) for ind in inds]))\n",
    "\n",
    "        # Split dataframes into sample list\n",
    "        # (multi-resolution: each list element contains multiple x and single y based on id_col)\n",
    "        dataset = []\n",
    "        for i, dat in enumerate(data):\n",
    "            dataset.append([ dat[inds[i].index(single_id)].drop(id_col,axis=1) for single_id in select_ids ])\n",
    "\n",
    "    else:\n",
    "        # Determine index labels in each input dataset is the same\n",
    "        dataset_indices = [ list(dataset.index) for dataset in args ]\n",
    "        select_ids = unique_list(dataset_indices)\n",
    "        \n",
    "        id_not_match_flag = !(len(data_length) == 1)\n",
    "        assert id_not_match_flag, \"Unmatch length in one or more data inputs (eg. x, y)!\"\n",
    "        select_ids = select_ids[0]\n",
    "        \n",
    "        # Split dataframes into sample list\n",
    "        # (equal resolution: each list element contains one row in both x and y)\n",
    "        dataset = []\n",
    "        for i, dat in enumerate(args):\n",
    "            dataset.append([ dat.loc[[single_id]] for single_id in select_ids ])\n",
    "\n",
    "    # Including index as one of the splitting dataset\n",
    "    dataset = dataset + [select_ids]\n",
    "    out = train_test_split(*dataset, test_size=test_ratio, random_state=random_state)\n",
    "    split_ids = out[-2:]\n",
    "    out = out[0:-2]\n",
    "\n",
    "    if report_id:\n",
    "        return(out, split_ids)\n",
    "    else:\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericData(Dataset):\n",
    "    def __init__(self, x, y, transform=None, dtype=torch.double, sample_ids=None):\n",
    "        assert (len(y) == len(x)), \"Number of x and y samples do not match!\"\n",
    "        self.len = len(y)\n",
    "        self.transform = transform\n",
    "        self.sample_ids = sample_ids\n",
    "        self.x, self.x_col = self._format_dataset(x, dtype)\n",
    "        self.y, self.y_col = self._format_dataset(y, dtype)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        sample = [self.x[index],\n",
    "                  self.y[index]]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def _format_dataset(self, d, dtype):\n",
    "        if type(d) == pd.core.frame.DataFrame:\n",
    "            # check to make sure that the sample_ids are the same as dataframe row index if sample_ids exist\n",
    "            if self.sample_ids is not None:\n",
    "                assert (len(unique_list([list(d.index),self.sample_ids])) == 1), \"Input data rowname/index not equal to sample_ids!\"\n",
    "            else:\n",
    "                self.sample_ids = list(d.index)\n",
    "            # extract column names\n",
    "            colname = d.columns\n",
    "        else:\n",
    "            colname = d[0].columns\n",
    "\n",
    "        # convert dataframe to list of a single row tensor\n",
    "        out = self._sample_type_convert(d, dtype)\n",
    "\n",
    "        return out, colname\n",
    "        \n",
    "    def _sample_type_convert(self, samples, dtype):\n",
    "        # since the input samples are list of single-row-dataframe, with dimension of 1 x Features\n",
    "        # to convert them into tensors, the row dimension is removed.\n",
    "        samples_out = [ torch.tensor(sample_ele.iloc[0]).type(dtype) for sample_ele in samples ]\n",
    "        return samples_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_k_fold_indices(n_samples, k=5, shuffle=False):\n",
    "    '''\n",
    "    Drawing sample indices for K-Fold\n",
    "    \n",
    "    Args:\n",
    "        samples: Number of samples in the dataset\n",
    "        shuffle: Shuffling of samples\n",
    "\n",
    "    Returns:\n",
    "        kfold_train_ind: Indices for training set\n",
    "        kfold_valid_ind: Indices for validation set\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    kfold = KFold(n_splits=k, shuffle=shuffle).split([*range(n_samples)])\n",
    "    i, kfold_ind = zip(*[*enumerate(kfold)])   # Expand the index obtained by the K-Fold function\n",
    "    kfold_train_ind, kfold_valid_ind = zip(*kfold_ind)\n",
    "    return(kfold_train_ind, kfold_valid_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ind(ls,ind):\n",
    "    return [ ls[i] for i in ind.tolist() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patitioned_data_object_numeric(x, y, test_split_ratio, k, random_state=25):\n",
    "    # Model/Test Splitting\n",
    "    (x_model, x_test, \n",
    "     y_model, y_test), (samples_id_model, samples_id_test) = model_test_split(x, y, \n",
    "                                                             test_ratio=test_split_ratio, \n",
    "                                                             report_id=True,\n",
    "                                                             random_state=random_state)\n",
    "    \n",
    "    # K-Fold Index Sampling\n",
    "    [kfold_train_ind, kfold_valid_ind] = get_k_fold_indices(n_samples=len(y_model), k=k, shuffle=False)   # Shuffle is NOT needed, since the samples were shuffled in the model/test split\n",
    "\n",
    "    # Create K-set of datasets for Pytorch data loader\n",
    "    dataset_train_kfold = [ NumericData(select_ind(x_model,fold_ind), \n",
    "                                        select_ind(y_model,fold_ind),\n",
    "                                        sample_ids = select_ind(samples_id_model, fold_ind)) \n",
    "                                           for fold_ind in kfold_train_ind ]\n",
    "    dataset_valid_kfold = [ NumericData(select_ind(x_model,fold_ind), \n",
    "                                        select_ind(y_model,fold_ind),\n",
    "                                        sample_ids = select_ind(samples_id_model, fold_ind)) \n",
    "                                           for fold_ind in kfold_valid_ind ]\n",
    "\n",
    "    # Create dataset for modeling and testing\n",
    "    dataset_model = NumericData(x_model, y_model, sample_ids = samples_id_model)\n",
    "    dataset_test = NumericData(x_test, y_test, sample_ids = samples_id_test)\n",
    "    \n",
    "    return dataset_model, dataset_test, dataset_train_kfold, dataset_valid_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuron Custom Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_partitions(n_ele, n_min=1, max_dim=None, recursion_level=1):\n",
    "    '''\n",
    "    Fast Integer Partitioning\n",
    "    Dividing a single integer into a list of integer that sums up to the given number\n",
    "    \n",
    "    Args:\n",
    "        num_ele: Total number of elements to be distributed\n",
    "        n_min: Minimum number of elements per output dimension\n",
    "\n",
    "    Returns:\n",
    "        Iterator as list of elements splitted into multiple dimensions\n",
    "        \n",
    "    Original Source :\n",
    "    (Modification made to speed up by skpping recurrsion exceed max_dim)\n",
    "        https://stackoverflow.com/questions/10035752/elegant-python-code-for-integer-partitioning\n",
    "    \n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    if (max_dim is not None) and (recursion_level > max_dim):\n",
    "        yield None\n",
    "    else:\n",
    "        yield (n_ele,)\n",
    "        for i in range(n_min, n_ele//2 + 1):\n",
    "            for p in integer_partitions(n_ele-i, i, max_dim, recursion_level+1):\n",
    "                if p is not None:\n",
    "                    yield (i,) + p\n",
    "                elif recursion_level != 1:\n",
    "                    yield None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sampling(num_ele, n_min=1, n_max=None, out_dim=None, n_samples=1, prepend=[], postpend=[], single_sample=False):\n",
    "    '''\n",
    "    Randomly split the elements into multiple dimensions\n",
    "    This is use for neuron sampling the number of elements and layer for multibranch neural network\n",
    "    \n",
    "    Args:\n",
    "        num_ele: Total number of elements to be distributed\n",
    "        n_min: Minimum number of elements per output dimension\n",
    "        n_max: Maximum number of elements per output dimension\n",
    "        out_dim: Number of output dimensions to distribute the element, random dimensions will be given with None given\n",
    "\n",
    "    Returns:\n",
    "        sample: List of elements splitted into multiple dimensions\n",
    "        \n",
    "    Raises:\n",
    "        -\n",
    "        \n",
    "    Example:\n",
    "        >>> split_sampling(14, n_min=2, out_dim=4)\n",
    "        [2, 5, 4, 3]\n",
    "        \n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    # !!! DEBUG !!!\n",
    "    # print(f\"num_ele: {num_ele}; n_min: {n_min}; out_dim: {out_dim}\")\n",
    "    \n",
    "    # Generate the Integer Partitions\n",
    "    splits = integer_partitions(num_ele, n_min=n_min, max_dim=out_dim)\n",
    "    if n_max is not None:\n",
    "        splits = [ split for split in splits if max(split) <= n_max ]\n",
    "    if out_dim is not None:\n",
    "        splits = [ split for split in splits if len(list(split)) == out_dim ]\n",
    "    else:\n",
    "        splits = [ split for split in splits ]\n",
    "    \n",
    "    # Filter with Number of Output Dimension\n",
    "    splits_perm = [list(set(itertools.permutations(split))) for split in splits ]\n",
    "    unique_splits_perm = list(itertools.chain.from_iterable(splits_perm))\n",
    "        \n",
    "    # Randomly Sample one of the permutation\n",
    "    if n_samples <= len(unique_splits_perm):\n",
    "        sample = list([ prepend+list(sample)+postpend for sample in random.sample(unique_splits_perm, k=n_samples)])\n",
    "    else:\n",
    "        sample = list([ prepend+list(sample)+postpend for sample in random.choices(unique_splits_perm, k=n_samples)])\n",
    "    if single_sample:\n",
    "        sample = sample[0]\n",
    "    \n",
    "    return(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fifo(y_est, y, sgrp=None, history=None, queue_len=1000):\n",
    "    '''\n",
    "    Record Loss of Output Data\n",
    "    Due to the variable input resolution, zero padding is required for batch gradient decent for cspd algorithm.  Therefore, the zero padded batches could introduce a bias in the loss metric computation.  To avoid this problem, the zero padded data with all zeros for the subgroup indicator is used to remove these entries during error computation.\n",
    "    \n",
    "    Args:\n",
    "        y_est: Model prediction output\n",
    "        y: Training data output ground truth\n",
    "        sgrp: Subgrouping one-hot-encoded matrix for the batch data (B x O x S matrix, where B is batch size, O is output dimensions, S is number of subgroups)\n",
    "        queue_len: Maximum records to be stored in the history queue\n",
    "\n",
    "    Returns:\n",
    "        history: Dictionary of output to be reported, each dictionary element is a numpy array as a queue containing the history of past results.\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Example:\n",
    "        \n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "       \n",
    "    # remove zero-padded cases\n",
    "    if sgrp is not None:\n",
    "        y_est, y, num_pts = remove_zero_padded(y_est, y, sgrp, return_length=True)\n",
    "    else:\n",
    "        assert y_est.shape[0] == y.shape[0], \"y and y_est has different shape\"\n",
    "        num_pts = y_est.shape[0]\n",
    "    \n",
    "    num_pts = min(num_pts, queue_len)   # if queue is smaller than the number of results, truncate the front\n",
    "    y_est = y_est[-num_pts:]\n",
    "    y = y[-num_pts:]\n",
    "        \n",
    "    # managing the results FIFO queue\n",
    "    # :: push new sample and remove older samples\n",
    "    # :: keep the y, y_est in a FIFO for computing statistics\n",
    "    if history is None or len(history) == 0:\n",
    "        # initialize for the queue\n",
    "        history = {'y': y, 'y_est': y_est}\n",
    "    elif len(history['y']) < queue_len:\n",
    "        # insert y into non-empty queue and trim data extended beyond queue size\n",
    "        history['y'] = torch.cat( (history['y'], y), dim=0)[-queue_len:]\n",
    "        history['y_est'] = torch.cat( (history['y_est'], y_est), dim=0)[-queue_len:]\n",
    "    else:\n",
    "        # shift element and replace (push on FIFO)\n",
    "        history['y'] = torch.roll(history['y'], -num_pts, dims=0)\n",
    "        history['y'][-num_pts:] = y\n",
    "        history['y_est'] = torch.roll(history['y_est'], -num_pts, dims=0)\n",
    "        history['y_est'][-num_pts:] = y_est\n",
    "    \n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iqr(e):\n",
    "    '''\n",
    "    Compute Loss IQR\n",
    "    \n",
    "    Args:\n",
    "        e: Error/Loss\n",
    "\n",
    "    Returns:\n",
    "        iqr: Interquartile range of the error\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Example:\n",
    "        \n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    q75 = torch.quantile(e, 0.75)\n",
    "    q25 = torch.quantile(e, 0.25)\n",
    "    iqr = q75 - q25\n",
    "    return iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l1_iqr(y_est, y):\n",
    "    '''\n",
    "    Compute L1 Loss IQR\n",
    "    \n",
    "    Args:\n",
    "        y_est: Model prediction output\n",
    "        y: Training data output ground truth\n",
    "\n",
    "    Returns:\n",
    "        iqr: Interquartile range of the error\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Example:\n",
    "        \n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    e = torch.abs(y_est - y)\n",
    "    q75 = torch.quantile(e, 0.75)\n",
    "    q25 = torch.quantile(e, 0.25)\n",
    "    iqr = q75 - q25\n",
    "    return iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape_iqr(y_est, y):\n",
    "    '''\n",
    "    Compute Error IQR\n",
    "    \n",
    "    Args:\n",
    "        y_est: Model prediction output\n",
    "        y: Training data output ground truth\n",
    "\n",
    "    Returns:\n",
    "        iqr: Interquartile range of the error\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Example:\n",
    "        \n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    e = torch.abs(y_est - y)\n",
    "    q75 = torch.quantile(e, 0.75)\n",
    "    q25 = torch.quantile(e, 0.25)\n",
    "    iqr = q75 - q25\n",
    "    return iqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray Tune Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training procedure\n",
    "def train_dnn_raytune(config, \n",
    "                      num_in_feat,\n",
    "                      criterion=nn.MSELoss(),\n",
    "                      checkpoint_dir=None, \n",
    "                      num_epochs=100, \n",
    "                      train_dataset=None, \n",
    "                      valid_dataset=None,\n",
    "                      metric_dict={'rmse':     lambda y_est,y: torch.sqrt(nn.MSELoss(reduction=\"mean\")(y_est,y)),\n",
    "                                   'mean_l1':  lambda y_est,y: nn.L1Loss(reduction=\"mean\")(y_est,y),\n",
    "                                   'l1_iqr':   lambda y_est,y: compute_iqr(nn.L1Loss(reduction=\"none\")(y_est,y)),\n",
    "                                   'med-ape':  lambda y_est,y: torch.median((y-y_est).abs()/y.abs()),\n",
    "                                   'mape':     lambda y_est,y: torch.mean((y-y_est).abs()/y.abs()),\n",
    "                                   'mape_iqr': lambda y_est,y: compute_iqr((y-y_est).abs()/y.abs())},\n",
    "                      train_metric_samples=None,\n",
    "                      force_cpu=False\n",
    "                     ):\n",
    "    '''\n",
    "    Training procedure for cspd regression with Ray Tune hyperparameter tuning\n",
    "    This function is to be used for training with hyperparameter tuning based on Ray Tune. A cspd architecture table is given and the following hyperparameters are sampled by Ray Tune:\n",
    "        lr: learning rate\n",
    "        h_branch: neural network architecture definition\n",
    "        dropout_p: dropout probability of all the neurons in the network\n",
    "        k: k-fold index k for the dataset\n",
    "        batch_size: the batch size use for the mini-batch use for batch gradient descent\n",
    "\n",
    "    Args:\n",
    "    (Note: This function is not meant to run directly by user, these arguemnts are passed indirectly by tune.run.)\n",
    "        config: Ray Tune hyperparameter sampling configuration (for details, please refer to: https://docs.ray.io/en/master/tune/user-guide.html)\n",
    "        checkpoint_dir: Output directory of training log, including the tensorboard output\n",
    "        num_epochs: Number of training epochs\n",
    "        num_in_feat: Number of input features for the network\n",
    "        num_branch: Number of parallel branches in the network (subgroups)\n",
    "        train_dataset: (List of or single) OutputDataBatch class Pytorch dataloader object\n",
    "        valid_dataset: (List of or single) OutputDataBatch class Pytorch dataloader object\n",
    "        metric_dict: Dictionary of loss function to be use for metric reporting (Attention: These are only used for reporting, not as training loss function!)\n",
    "\n",
    "    Returns:\n",
    "        result is return indirectly with tune.run\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Example:\n",
    "        -\n",
    "    '''\n",
    "\n",
    "    #====================== Ray Tune Parameters Setup ======================#\n",
    "\n",
    "    if 'dropout_p' in config.keys():\n",
    "        _dropout_p = config['dropout_p']\n",
    "    else:\n",
    "        _dropout_p = 0\n",
    "\n",
    "    if 'batch_size' in config.keys():\n",
    "        _batch_size = config['batch_size']\n",
    "    else:\n",
    "        _batch_size = 1\n",
    "        \n",
    "    # determine if input is k-fold dataset or single dataset\n",
    "    if (type(train_dataset) is list) and (type(valid_dataset) is list) and ('k' in config.keys()):\n",
    "        _train_dataset = train_dataset[config['k']]\n",
    "        _valid_dataset = valid_dataset[config['k']]\n",
    "    else:\n",
    "        _train_dataset = train_dataset\n",
    "        _valid_dataset = valid_dataset\n",
    "        \n",
    "    # measure error metric across whole epoch if no sample length is given\n",
    "    # (the latest progress might not be shown properly and error could be overestimated by earlier samples)\n",
    "    if train_metric_samples is None:\n",
    "        train_metric_samples = len(_train_dataset)\n",
    "    \n",
    "    # gpu usage\n",
    "    if not force_cpu:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=_train_dataset, batch_size=_batch_size, shuffle=True, \n",
    "                                               collate_fn=lambda x: [ x_ele.to(device) for x_ele in default_collate(x) ] )\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=_valid_dataset, batch_size=_batch_size, shuffle=True,\n",
    "                                               collate_fn=lambda x: [ x_ele.to(device) for x_ele in default_collate(x) ] )\n",
    "\n",
    "    #====================== Model Setup ======================#\n",
    "\n",
    "    # initialize ANN architecture\n",
    "    model = dnn(in_feat = num_in_feat, \n",
    "                layers = config['h_layers'], \n",
    "                dropout_p = _dropout_p,\n",
    "                act_fn = torch.relu)\n",
    "    model.apply(initialize_weights)\n",
    "\n",
    "    # gpu usage\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)   # for multiple GPUs\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    # optimizer is controlled by ray tune hyperparameter\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = config[\"lr\"])\n",
    "    \n",
    "    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint\n",
    "    # should be restored.\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "    \n",
    "    # create loss metric dictionary to store results\n",
    "    history = {'train': {}, 'valid': {}}\n",
    "    metric_output = {}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        #====================== Training ======================#\n",
    "\n",
    "        # training using all training samples\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # set the model to training mode\n",
    "            model.train()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            y_est = model(x)\n",
    "            loss = criterion(y_est, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # record the prediction results\n",
    "            # :: the following function is use to remove zero-padded samples in batch training\n",
    "            # :: loss metrics are kept in a FIFO queue per latest samples in order to compute statistics\n",
    "            history['train'] = loss_fifo(y_est, y, history=history['train'], queue_len=train_metric_samples)\n",
    "            \n",
    "        #====================== Validation ======================#\n",
    "        \n",
    "        # set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # training using all validation samples\n",
    "        with torch.no_grad():\n",
    "            for  i, (x, y) in enumerate(valid_loader):\n",
    "                y_est = model(x)\n",
    "                # record the prediction results\n",
    "                # :: the following function is use to remove zero-padded samples in batch training\n",
    "                # :: loss metrics are kept in a FIFO queue per latest samples in order to compute statistics\n",
    "                history['valid'] = loss_fifo(y_est, y, history=history['valid'], queue_len=len(_valid_dataset))\n",
    "                \n",
    "        for metric in metric_dict.keys():\n",
    "            for dataset in history.keys():\n",
    "                metric_label = '_'.join([dataset,metric])\n",
    "                metric_output[metric_label] = metric_dict[metric](history[dataset]['y_est'],history[dataset]['y']).item()\n",
    "                \n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and will potentially be passed as the `checkpoint_dir`\n",
    "        # parameter in future iterations.\n",
    "        with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save( (model.state_dict(), optimizer.state_dict()), path )\n",
    "\n",
    "        tune.report(**metric_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training routine to be use for manual training with __No Hyperparameter Tuning__ with Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training procedure\n",
    "def train_dnn(model, train_dataset, valid_dataset, criterion, optimizer, \n",
    "              epochs=100, \n",
    "              batch_size=1, \n",
    "              metric_dict={'rmse':     lambda y_est,y: torch.sqrt(nn.MSELoss(reduction=\"mean\")(y_est,y)),\n",
    "                           'mean_l1':  lambda y_est,y: nn.L1Loss(reduction=\"mean\")(y_est,y),\n",
    "                           'l1_iqr':   lambda y_est,y: compute_iqr(nn.L1Loss(reduction=\"none\")(y_est,y)),\n",
    "                           'med-ape':  lambda y_est,y: torch.median((y-y_est).abs()/y.abs()),\n",
    "                           'mape':     lambda y_est,y: torch.mean((y-y_est).abs()/y.abs()),\n",
    "                           'mape_iqr': lambda y_est,y: compute_iqr((y-y_est).abs()/y.abs())},\n",
    "              train_metric_samples=None,\n",
    "              ):\n",
    "    '''\n",
    "    Training procedure for cspd regression\n",
    "    This function is to be used for training without hyperparameter optimization, this function is usually use for test run to make sure all modification on the cspd architecture is working before submitting a list of models for hyperparameter search. To use hyperparameter optimization, please use either `train_cspd_raytune` or `train_cspd_raytune_auto_architecture`.\n",
    "    \n",
    "    Args:\n",
    "        model: Pytorch model object of cspd\n",
    "        train_dataset: OutputDataBatch or OutputData class Pytorch dataloader object\n",
    "        valid_dataset: OutputDataBatch or OutputData class Pytorch dataloader object\n",
    "        criterion: Training criterion to be used (eg. criterion = nn.MSELoss())\n",
    "        optimizer: Training optimizer to be used (eg. optimizer = torch.optim.Adam(model.parameters(), lr = 0.1))\n",
    "        epochs: Number of training epochs to be used\n",
    "        batch_size: The batch size to use for batch gradient descent of the output dimension, the input dimension will be setted to zero patching within the OutputDataBatch object for comparable input size to perform the stacked computation\n",
    "        metric_dict: Dictionary of loss function to be use for metric reporting (Attention: These are only used for reporting, not as training loss function!)\n",
    "        history_queue_len: The number of loss result samples to keep for statistical reporting\n",
    "\n",
    "    Returns:\n",
    "        history: Training and validation results summary\n",
    "        model: Implicitly updated in the model object\n",
    "\n",
    "    Raises:\n",
    "        -\n",
    "\n",
    "    Example:\n",
    "        # Example of cspd training with no subgroupings\n",
    "        # (Remark: s_model and s_test are all generated with all 1's by model_test_split function with ohe_cols=None)\n",
    "        (x_model, x_test, s_model, s_test, y_model, y_test) = model_test_split(x, y, ohe_cols=None, id_col=y_id_col, test_size=0.3, random_state=25)\n",
    "        dataset_train = OutputDataBatch(x_model, s_model, y_model, zero_patch = False)\n",
    "        dataset_valid = OutputDataBatch(x_test, s_test, y_test, zero_patch = False)\n",
    "        architecture = [2,2,3,2,2]   # single branch with 5 layers\n",
    "        model = dnn(in_feat=10, layers=architecture, dropout_p=0.3)\n",
    "        model.apply(initialize_weights)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n",
    "        criterion = nn.MSELoss()\n",
    "        metric_dict = {'rmse': lambda y_est,y: torch.sqrt(nn.MSELoss(reduction=\"none\")(y_est,y)), \n",
    "                       'mape': lambda y_est,y: (y-y_est).abs()/y.abs()}\n",
    "        training_results = train_cspd(model=model, \n",
    "                                      train_dataset=dataset_model, \n",
    "                                      valid_dataset=dataset_test, \n",
    "                                      criterion=criterion,\n",
    "                                      optimizer=optimizer,\n",
    "                                      metric_dict=metric_dict,\n",
    "                                      epochs=num_epochs, \n",
    "                                      batch_size=64)        \n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    history = {'train': {}, 'valid': {}}\n",
    "    metric_output = {}\n",
    "\n",
    "    if train_metric_samples is None:\n",
    "        train_metric_samples = len(train_dataset)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        #====================== Training ======================#\n",
    "\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "\n",
    "        # training using all training samples\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # set the model to training mode\n",
    "            model.train()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            y_est = model(x)\n",
    "            loss = criterion(y_est, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            history['train'] = loss_fifo(y_est, y, history=history['train'], queue_len=train_metric_samples)\n",
    "\n",
    "        #====================== Validation ======================#\n",
    "        \n",
    "        # set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # training using all validation samples\n",
    "        with torch.no_grad():\n",
    "            for  i, (x, y) in enumerate(valid_loader):\n",
    "                y_est = model(x)\n",
    "                history['valid'] = loss_fifo(y_est, y, history=history['valid'], queue_len=len(valid_dataset))\n",
    "    \n",
    "        metric_labels = []\n",
    "        for metric in metric_dict.keys():\n",
    "            for dataset in history.keys():\n",
    "                metric_label = '_'.join([dataset,metric])\n",
    "                metric_output[metric_label] = metric_dict[metric](history[dataset]['y_est'],history[dataset]['y']).item()\n",
    "                metric_labels.append(metric_label)\n",
    "                        \n",
    "        print(f\"[Epoch: { epoch+1 }]\", end=\" \" )\n",
    "        for metric_label in metric_labels:\n",
    "            print(f\"{metric_label}: {metric_output[metric_label]:.3f},\", end=\" \")\n",
    "        print(f\"\")\n",
    "\n",
    "    return (history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dnn_raytune_cpu_gpu_distributed(config, \n",
    "                                          num_in_feat,\n",
    "                                          criterion=nn.MSELoss(),\n",
    "                                          checkpoint_dir=None, \n",
    "                                          num_epochs=100, \n",
    "                                          train_dataset=None, \n",
    "                                          valid_dataset=None,\n",
    "                                          metric_dict={'rmse':     lambda y_est,y: torch.sqrt(nn.MSELoss(reduction=\"mean\")(y_est,y)),\n",
    "                                                       'mean_l1':  lambda y_est,y: nn.L1Loss(reduction=\"mean\")(y_est,y),\n",
    "                                                       'l1_iqr':   lambda y_est,y: compute_iqr(nn.L1Loss(reduction=\"none\")(y_est,y)),\n",
    "                                                       'med-ape':  lambda y_est,y: torch.median((y-y_est).abs()/y.abs()),\n",
    "                                                       'mape':     lambda y_est,y: torch.mean((y-y_est).abs()/y.abs()),\n",
    "                                                       'mape_iqr': lambda y_est,y: compute_iqr((y-y_est).abs()/y.abs())},\n",
    "                                          train_metric_samples=None,\n",
    "                                          ):\n",
    "    '''\n",
    "    CPU/GPU Distributed Wrapper Function for Training procedure for cspd regression\n",
    "    This function is written to allow training done on both CPU and GPU of a single machine at the same time.\n",
    "    \n",
    "    Args:\n",
    "\n",
    "    Returns:\n",
    "        result: Training metric results\n",
    "\n",
    "    Source:\n",
    "        This code is modified from the following: https://discuss.ray.io/t/different-trial-on-cpu-and-gpu-separately/2883\n",
    "\n",
    "    Author:\n",
    "        Dr. Calvin Chan\n",
    "        calvin.chan@bayer.com\n",
    "    '''\n",
    "    \n",
    "    a = filelock.FileLock(\"/tmp/gpu.lock\")\n",
    "    try:\n",
    "        # Makes it so that 1 trial will use the GPU at once.\n",
    "        a.acquire(timeout=1)\n",
    "        result = train_dnn_raytune(config, \n",
    "                                   num_in_feat,\n",
    "                                   criterion,\n",
    "                                   checkpoint_dir, \n",
    "                                   num_epochs, \n",
    "                                   train_dataset, \n",
    "                                   valid_dataset,\n",
    "                                   metric_dict,\n",
    "                                   train_metric_samples,\n",
    "                                   force_cpu=False\n",
    "                                   )\n",
    "    except filelock.Timeout:\n",
    "        # If the lock is acquired, you can just use CPU, and disable GPU access.\n",
    "        result = train_dnn_raytune(config, \n",
    "                                   num_in_feat,\n",
    "                                   criterion,\n",
    "                                   checkpoint_dir, \n",
    "                                   num_epochs, \n",
    "                                   train_dataset, \n",
    "                                   valid_dataset,\n",
    "                                   metric_dict,\n",
    "                                   train_metric_samples,\n",
    "                                   force_cpu=True\n",
    "                                   )\n",
    "    finally:\n",
    "        # Release the lock after training is done.\n",
    "        a.release()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_model, x_test, \n",
    " y_model, y_test), (samples_id_model, samples_id_test) = model_test_split(x, y, \n",
    "                                                         test_ratio=test_split_ratio, \n",
    "                                                         report_id=True,\n",
    "                                                         random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_model, dataset_test, dataset_train_kfold, dataset_valid_kfold = patitioned_data_object_numeric(x, y, test_split_ratio, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0293, -0.9659, -0.5685, -0.9649], dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_valid_kfold[0].x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for Joining Results and Architecture Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nested_numeric_to_string(in_list):\n",
    "    return(' ; '.join([' '.join([str(c) for c in lst]) for lst in in_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_nested(left, right, on):\n",
    "    left['key'] = left[on].apply(convert_nested_numeric_to_string)\n",
    "    right['key'] = right[on].apply(convert_nested_numeric_to_string)\n",
    "    out = pd.merge(left.drop(columns=[on]), right, on='key', how='left')\n",
    "    out = out.drop(columns=['key'])\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (Ray Tune using Auto Network Architecture Tunning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_metrics = [\"training_iteration\",\n",
    "                  \"train_rmse\", \n",
    "                  \"valid_rmse\",\n",
    "                  \"train_mean_l1\", \n",
    "                  \"valid_mean_l1\",\n",
    "                  \"train_l1_iqr\",\n",
    "                  \"valid_l1_iqr\",\n",
    "                  \"train_med-ape\",\n",
    "                  \"valid_med-ape\",\n",
    "                  \"train_mape\", \n",
    "                  \"valid_mape\",\n",
    "                  \"train_mape_iqr\", \n",
    "                  \"valid_mape_iqr\",\n",
    "                 ]\n",
    "\n",
    "\n",
    "reporter = tune.JupyterNotebookReporter(overwrite=False, max_progress_rows=35, metric_columns= report_metrics)\n",
    "scheduler = HyperBandScheduler(metric=\"valid_mape\", mode=\"min\", max_t=num_epochs)\n",
    "searchopt = BasicVariantGenerator(max_concurrent=15)\n",
    "\n",
    "config = {\"lr\": tune.loguniform(lr_min, lr_max),                       # Learning Rate\n",
    "          \"dropout_p\": tune.uniform(dropout_p_min, dropout_p_max),     # Dropout On/Off\n",
    "          \"k\": tune.grid_search([*range(k)]),                          # K-Fold Index\n",
    "          \"batch_size\": tune.choice(batch_size),                       # 1: SGD; 2+: Zero-Filled BGD\n",
    "          \"h_total\": tune.choice([*range(h_total_min, h_total_max, h_total_step)]),\n",
    "          \"h_layers\": tune.sample_from(lambda spec: split_sampling(num_ele = spec.config.h_total, \n",
    "                                                                   n_min = h_min_neuron_per_layer,\n",
    "                                                                   n_max = h_max_neuron_per_layer,\n",
    "                                                                   out_dim = h_max_layer,\n",
    "                                                                   single_sample = True)),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 2.0/59.9 GiB<br>Using HyperBand: num_stopped=0 total_brackets=2\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=2, Milestone (r)=5, completed=0.0%): {PENDING: 1, RUNNING: 1} \n",
       "  Bracket(Max Size (n)=3, Milestone (r)=1, completed=0.0%): {PENDING: 3} <br>Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/35.31 GiB heap, 0.0/17.65 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/calvin_chan/data/output/checkpoint/testing/train_dnn_raytune_cpu_gpu_distributed_2022-03-25_16-00-08<br>Number of trials: 5/5 (4 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                       </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_p</th><th>h_layers    </th><th style=\"text-align: right;\">  h_total</th><th style=\"text-align: right;\">  k</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.0921763 </td><td>[3, 5, 2]   </td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0.000164085</td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.363724  </td><td>[2, 2, 4]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">0.0988601  </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.586927  </td><td>[4, 2, 2, 2]</td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">0.00569188 </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.00683811</td><td>[2, 4, 2]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">0.0185841  </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.25734   </td><td>[2, 2, 2, 2]</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\">0.000352712</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00000:\n",
      "  date: 2022-03-25_16-00-12\n",
      "  done: false\n",
      "  experiment_id: 4706dda29d2349a793d93a2f472b9a8c\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 979\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.626666784286499\n",
      "  time_this_iter_s: 2.626666784286499\n",
      "  time_total_s: 2.626666784286499\n",
      "  timestamp: 1648224012\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 36411.15439262513\n",
      "  train_mape: 0.9998978541395598\n",
      "  train_mape_iqr: 8.452889486720849e-05\n",
      "  train_mean_l1: 38239.8253584498\n",
      "  train_med-ape: 0.9999726874861796\n",
      "  train_rmse: 44107.711333706655\n",
      "  training_iteration: 1\n",
      "  trial_id: a36cc_00000\n",
      "  valid_l1_iqr: 39577.89798053116\n",
      "  valid_mape: 0.9999145795114288\n",
      "  valid_mape_iqr: 6.153741725434259e-05\n",
      "  valid_mean_l1: 39761.06219371004\n",
      "  valid_med-ape: 0.9999676453376549\n",
      "  valid_rmse: 45778.74130960422\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 2.0/59.9 GiB<br>Using HyperBand: num_stopped=0 total_brackets=2\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=2, Milestone (r)=5, completed=50.0%): {PAUSED: 1, PENDING: 1} \n",
       "  Bracket(Max Size (n)=3, Milestone (r)=1, completed=0.0%): {PENDING: 2, RUNNING: 1} <br>Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/35.31 GiB heap, 0.0/17.65 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/calvin_chan/data/output/checkpoint/testing/train_dnn_raytune_cpu_gpu_distributed_2022-03-25_16-00-08<br>Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                       </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_p</th><th>h_layers    </th><th style=\"text-align: right;\">  h_total</th><th style=\"text-align: right;\">  k</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_rmse</th><th style=\"text-align: right;\">  valid_rmse</th><th style=\"text-align: right;\">  train_mean_l1</th><th style=\"text-align: right;\">  valid_mean_l1</th><th style=\"text-align: right;\">  train_l1_iqr</th><th style=\"text-align: right;\">  valid_l1_iqr</th><th style=\"text-align: right;\">  train_med-ape</th><th style=\"text-align: right;\">  valid_med-ape</th><th style=\"text-align: right;\">  train_mape</th><th style=\"text-align: right;\">  valid_mape</th><th style=\"text-align: right;\">  train_mape_iqr</th><th style=\"text-align: right;\">  valid_mape_iqr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.586927  </td><td>[4, 2, 2, 2]</td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">0.00569188 </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.0921763 </td><td>[3, 5, 2]   </td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0.000164085</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">     44601.4</td><td style=\"text-align: right;\">     45778.3</td><td style=\"text-align: right;\">        38378.5</td><td style=\"text-align: right;\">        39760.5</td><td style=\"text-align: right;\">         39254</td><td style=\"text-align: right;\">       39577.8</td><td style=\"text-align: right;\">       0.999958</td><td style=\"text-align: right;\">       0.999954</td><td style=\"text-align: right;\">    0.999851</td><td style=\"text-align: right;\">    0.999884</td><td style=\"text-align: right;\">     0.000103582</td><td style=\"text-align: right;\">     8.52046e-05</td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.363724  </td><td>[2, 2, 4]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">0.0988601  </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.00683811</td><td>[2, 4, 2]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">0.0185841  </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.25734   </td><td>[2, 2, 2, 2]</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\">0.000352712</td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00002:\n",
      "  date: 2022-03-25_16-00-16\n",
      "  done: false\n",
      "  experiment_id: 3d0773acb7a14be8936efcf6c5dc611b\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 982\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.7220420837402344\n",
      "  time_this_iter_s: 2.7220420837402344\n",
      "  time_total_s: 2.7220420837402344\n",
      "  timestamp: 1648224016\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 37647.5\n",
      "  train_mape: 1.0\n",
      "  train_mape_iqr: 0.0\n",
      "  train_mean_l1: 40618.221875\n",
      "  train_med-ape: 1.0\n",
      "  train_rmse: 46263.6169199472\n",
      "  training_iteration: 1\n",
      "  trial_id: a36cc_00002\n",
      "  valid_l1_iqr: 41511.0\n",
      "  valid_mape: 1.0\n",
      "  valid_mape_iqr: 0.0\n",
      "  valid_mean_l1: 39166.08125\n",
      "  valid_med-ape: 1.0\n",
      "  valid_rmse: 45520.772548159264\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 2.0/59.9 GiB<br>Using HyperBand: num_stopped=0 total_brackets=2\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=2, Milestone (r)=5, completed=50.0%): {PAUSED: 1, PENDING: 1} \n",
       "  Bracket(Max Size (n)=3, Milestone (r)=1, completed=16.7%): {PAUSED: 1, PENDING: 1, RUNNING: 1} <br>Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/35.31 GiB heap, 0.0/17.65 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/calvin_chan/data/output/checkpoint/testing/train_dnn_raytune_cpu_gpu_distributed_2022-03-25_16-00-08<br>Number of trials: 5/5 (2 PAUSED, 2 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                       </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_p</th><th>h_layers    </th><th style=\"text-align: right;\">  h_total</th><th style=\"text-align: right;\">  k</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_rmse</th><th style=\"text-align: right;\">  valid_rmse</th><th style=\"text-align: right;\">  train_mean_l1</th><th style=\"text-align: right;\">  valid_mean_l1</th><th style=\"text-align: right;\">  train_l1_iqr</th><th style=\"text-align: right;\">  valid_l1_iqr</th><th style=\"text-align: right;\">  train_med-ape</th><th style=\"text-align: right;\">  valid_med-ape</th><th style=\"text-align: right;\">  train_mape</th><th style=\"text-align: right;\">  valid_mape</th><th style=\"text-align: right;\">  train_mape_iqr</th><th style=\"text-align: right;\">  valid_mape_iqr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.00683811</td><td>[2, 4, 2]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">0.0185841  </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.0921763 </td><td>[3, 5, 2]   </td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0.000164085</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">     44601.4</td><td style=\"text-align: right;\">     45778.3</td><td style=\"text-align: right;\">        38378.5</td><td style=\"text-align: right;\">        39760.5</td><td style=\"text-align: right;\">       39254  </td><td style=\"text-align: right;\">       39577.8</td><td style=\"text-align: right;\">       0.999958</td><td style=\"text-align: right;\">       0.999954</td><td style=\"text-align: right;\">    0.999851</td><td style=\"text-align: right;\">    0.999884</td><td style=\"text-align: right;\">     0.000103582</td><td style=\"text-align: right;\">     8.52046e-05</td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.586927  </td><td>[4, 2, 2, 2]</td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">0.00569188 </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">     46263.6</td><td style=\"text-align: right;\">     45520.8</td><td style=\"text-align: right;\">        40618.2</td><td style=\"text-align: right;\">        39166.1</td><td style=\"text-align: right;\">       37647.5</td><td style=\"text-align: right;\">       41511  </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">     0          </td><td style=\"text-align: right;\">     0          </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.363724  </td><td>[2, 2, 4]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">0.0988601  </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.25734   </td><td>[2, 2, 2, 2]</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\">0.000352712</td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00003:\n",
      "  date: 2022-03-25_16-00-20\n",
      "  done: false\n",
      "  experiment_id: eaee5fa59c044daf9abb1c0b9a9a1eb5\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 983\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.529177665710449\n",
      "  time_this_iter_s: 2.529177665710449\n",
      "  time_total_s: 2.529177665710449\n",
      "  timestamp: 1648224020\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 41454.25\n",
      "  train_mape: 1.0\n",
      "  train_mape_iqr: 0.0\n",
      "  train_mean_l1: 38703.4375\n",
      "  train_med-ape: 1.0\n",
      "  train_rmse: 44938.01115543778\n",
      "  training_iteration: 1\n",
      "  trial_id: a36cc_00003\n",
      "  valid_l1_iqr: 37635.5\n",
      "  valid_mape: 1.0\n",
      "  valid_mape_iqr: 0.0\n",
      "  valid_mean_l1: 41044.505\n",
      "  valid_med-ape: 1.0\n",
      "  valid_rmse: 46733.981796065695\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 2.0/59.9 GiB<br>Using HyperBand: num_stopped=0 total_brackets=2\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=2, Milestone (r)=5, completed=50.0%): {PAUSED: 1, PENDING: 1} \n",
       "  Bracket(Max Size (n)=3, Milestone (r)=1, completed=33.3%): {PAUSED: 2, RUNNING: 1} <br>Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/35.31 GiB heap, 0.0/17.65 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/calvin_chan/data/output/checkpoint/testing/train_dnn_raytune_cpu_gpu_distributed_2022-03-25_16-00-08<br>Number of trials: 5/5 (3 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                       </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_p</th><th>h_layers    </th><th style=\"text-align: right;\">  h_total</th><th style=\"text-align: right;\">  k</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_rmse</th><th style=\"text-align: right;\">  valid_rmse</th><th style=\"text-align: right;\">  train_mean_l1</th><th style=\"text-align: right;\">  valid_mean_l1</th><th style=\"text-align: right;\">  train_l1_iqr</th><th style=\"text-align: right;\">  valid_l1_iqr</th><th style=\"text-align: right;\">  train_med-ape</th><th style=\"text-align: right;\">  valid_med-ape</th><th style=\"text-align: right;\">  train_mape</th><th style=\"text-align: right;\">  valid_mape</th><th style=\"text-align: right;\">  train_mape_iqr</th><th style=\"text-align: right;\">  valid_mape_iqr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00004</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.25734   </td><td>[2, 2, 2, 2]</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\">0.000352712</td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.0921763 </td><td>[3, 5, 2]   </td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0.000164085</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">     44601.4</td><td style=\"text-align: right;\">     45778.3</td><td style=\"text-align: right;\">        38378.5</td><td style=\"text-align: right;\">        39760.5</td><td style=\"text-align: right;\">       39254  </td><td style=\"text-align: right;\">       39577.8</td><td style=\"text-align: right;\">       0.999958</td><td style=\"text-align: right;\">       0.999954</td><td style=\"text-align: right;\">    0.999851</td><td style=\"text-align: right;\">    0.999884</td><td style=\"text-align: right;\">     0.000103582</td><td style=\"text-align: right;\">     8.52046e-05</td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.586927  </td><td>[4, 2, 2, 2]</td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">0.00569188 </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">     46263.6</td><td style=\"text-align: right;\">     45520.8</td><td style=\"text-align: right;\">        40618.2</td><td style=\"text-align: right;\">        39166.1</td><td style=\"text-align: right;\">       37647.5</td><td style=\"text-align: right;\">       41511  </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">     0          </td><td style=\"text-align: right;\">     0          </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.00683811</td><td>[2, 4, 2]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">0.0185841  </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">     44938  </td><td style=\"text-align: right;\">     46734  </td><td style=\"text-align: right;\">        38703.4</td><td style=\"text-align: right;\">        41044.5</td><td style=\"text-align: right;\">       41454.2</td><td style=\"text-align: right;\">       37635.5</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">     0          </td><td style=\"text-align: right;\">     0          </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.363724  </td><td>[2, 2, 4]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">0.0988601  </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00002:\n",
      "  date: 2022-03-25_16-00-16\n",
      "  done: false\n",
      "  experiment_id: 3d0773acb7a14be8936efcf6c5dc611b\n",
      "  experiment_tag: 2_batch_size=64,dropout_p=0.58693,h_layers=[4, 2, 2, 2],h_total=10,k=2,lr=0.0056919\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 982\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.7220420837402344\n",
      "  time_this_iter_s: 2.7220420837402344\n",
      "  time_total_s: 2.7220420837402344\n",
      "  timestamp: 1648224016\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 37647.5\n",
      "  train_mape: 1.0\n",
      "  train_mape_iqr: 0.0\n",
      "  train_mean_l1: 40618.221875\n",
      "  train_med-ape: 1.0\n",
      "  train_rmse: 46263.6169199472\n",
      "  training_iteration: 1\n",
      "  trial_id: a36cc_00002\n",
      "  valid_l1_iqr: 41511.0\n",
      "  valid_mape: 1.0\n",
      "  valid_mape_iqr: 0.0\n",
      "  valid_mean_l1: 39166.08125\n",
      "  valid_med-ape: 1.0\n",
      "  valid_rmse: 45520.772548159264\n",
      "  \n",
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00004:\n",
      "  date: 2022-03-25_16-00-24\n",
      "  done: false\n",
      "  experiment_id: 6f6b8a3f3c9548ceab813936dbea5647\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 4093\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.5124237537384033\n",
      "  time_this_iter_s: 2.5124237537384033\n",
      "  time_total_s: 2.5124237537384033\n",
      "  timestamp: 1648224024\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 37125.49426996411\n",
      "  train_mape: 0.9999992378450908\n",
      "  train_mape_iqr: 4.703508046377536e-07\n",
      "  train_mean_l1: 39839.20626088792\n",
      "  train_med-ape: 0.9999996060748931\n",
      "  train_rmse: 45527.72000322124\n",
      "  training_iteration: 1\n",
      "  trial_id: a36cc_00004\n",
      "  valid_l1_iqr: 39402.5054654734\n",
      "  valid_mape: 0.999999353574916\n",
      "  valid_mape_iqr: 5.614831031230949e-07\n",
      "  valid_mean_l1: 38718.57200730939\n",
      "  valid_med-ape: 0.9999997779462605\n",
      "  valid_rmse: 44964.23749456449\n",
      "  \n",
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00004:\n",
      "  date: 2022-03-25_16-00-24\n",
      "  done: true\n",
      "  experiment_id: 6f6b8a3f3c9548ceab813936dbea5647\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 4093\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.7014124393463135\n",
      "  time_this_iter_s: 0.08869600296020508\n",
      "  time_total_s: 2.7014124393463135\n",
      "  timestamp: 1648224024\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 39077.73717669734\n",
      "  train_mape: 0.9999964220043985\n",
      "  train_mape_iqr: 2.251945790177068e-06\n",
      "  train_mean_l1: 39656.404454493444\n",
      "  train_med-ape: 0.9999983921252986\n",
      "  train_rmse: 45399.27338897037\n",
      "  training_iteration: 3\n",
      "  trial_id: a36cc_00004\n",
      "  valid_l1_iqr: 39402.48567902027\n",
      "  valid_mape: 0.9999967939731775\n",
      "  valid_mape_iqr: 2.714872336273544e-06\n",
      "  valid_mean_l1: 38718.5295560986\n",
      "  valid_med-ape: 0.9999986496828672\n",
      "  valid_rmse: 44964.20029277969\n",
      "  \n",
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00001:\n",
      "  date: 2022-03-25_16-00-28\n",
      "  done: false\n",
      "  experiment_id: d4f2748d5eb64d1fb38c2805dac54a7c\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 4120\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.552229642868042\n",
      "  time_this_iter_s: 2.552229642868042\n",
      "  time_total_s: 2.552229642868042\n",
      "  timestamp: 1648224028\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 38209.15756117895\n",
      "  train_mape: 0.9570625389051448\n",
      "  train_mape_iqr: 0.02841616745448783\n",
      "  train_mean_l1: 38511.749902168114\n",
      "  train_med-ape: 0.9951494074738743\n",
      "  train_rmse: 44643.42937339006\n",
      "  training_iteration: 1\n",
      "  trial_id: a36cc_00001\n",
      "  valid_l1_iqr: 38136.54963828252\n",
      "  valid_mape: 0.913300841829745\n",
      "  valid_mape_iqr: 0.06714880424306469\n",
      "  valid_mean_l1: 37869.06857288107\n",
      "  valid_med-ape: 0.9580194232484591\n",
      "  valid_rmse: 43876.41476278966\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 2.1/59.9 GiB<br>Using HyperBand: num_stopped=2 total_brackets=2\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=2, Milestone (r)=5, completed=90.0%): {PAUSED: 1, RUNNING: 1} \n",
       "  Bracket(Max Size (n)=1, Milestone (r)=3, completed=100.0%): {TERMINATED: 3} <br>Resources requested: 1.0/8 CPUs, 1.0/1 GPUs, 0.0/35.31 GiB heap, 0.0/17.65 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/calvin_chan/data/output/checkpoint/testing/train_dnn_raytune_cpu_gpu_distributed_2022-03-25_16-00-08<br>Number of trials: 5/5 (1 PAUSED, 1 RUNNING, 3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                       </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_p</th><th>h_layers    </th><th style=\"text-align: right;\">  h_total</th><th style=\"text-align: right;\">  k</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_rmse</th><th style=\"text-align: right;\">  valid_rmse</th><th style=\"text-align: right;\">  train_mean_l1</th><th style=\"text-align: right;\">  valid_mean_l1</th><th style=\"text-align: right;\">  train_l1_iqr</th><th style=\"text-align: right;\">  valid_l1_iqr</th><th style=\"text-align: right;\">  train_med-ape</th><th style=\"text-align: right;\">  valid_med-ape</th><th style=\"text-align: right;\">  train_mape</th><th style=\"text-align: right;\">  valid_mape</th><th style=\"text-align: right;\">  train_mape_iqr</th><th style=\"text-align: right;\">  valid_mape_iqr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00001</td><td>RUNNING   </td><td>10.123.137.245:4120</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.363724  </td><td>[2, 2, 4]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">0.0988601  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">     37570.4</td><td style=\"text-align: right;\">     32454  </td><td style=\"text-align: right;\">        31587.9</td><td style=\"text-align: right;\">        26320  </td><td style=\"text-align: right;\">       34114.9</td><td style=\"text-align: right;\">       33418.5</td><td style=\"text-align: right;\">       0.994761</td><td style=\"text-align: right;\">       0.656561</td><td style=\"text-align: right;\">    1.22093 </td><td style=\"text-align: right;\">    0.785931</td><td style=\"text-align: right;\">     0.394726   </td><td style=\"text-align: right;\">     0.310706   </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00000</td><td>PAUSED    </td><td>                   </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.0921763 </td><td>[3, 5, 2]   </td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0.000164085</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">     44601.4</td><td style=\"text-align: right;\">     45778.3</td><td style=\"text-align: right;\">        38378.5</td><td style=\"text-align: right;\">        39760.5</td><td style=\"text-align: right;\">       39254  </td><td style=\"text-align: right;\">       39577.8</td><td style=\"text-align: right;\">       0.999958</td><td style=\"text-align: right;\">       0.999954</td><td style=\"text-align: right;\">    0.999851</td><td style=\"text-align: right;\">    0.999884</td><td style=\"text-align: right;\">     0.000103582</td><td style=\"text-align: right;\">     8.52046e-05</td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00002</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.586927  </td><td>[4, 2, 2, 2]</td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">0.00569188 </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">     46263.6</td><td style=\"text-align: right;\">     45520.8</td><td style=\"text-align: right;\">        40618.2</td><td style=\"text-align: right;\">        39166.1</td><td style=\"text-align: right;\">       37647.5</td><td style=\"text-align: right;\">       41511  </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">     0          </td><td style=\"text-align: right;\">     0          </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00003</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.00683811</td><td>[2, 4, 2]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">0.0185841  </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">     44938  </td><td style=\"text-align: right;\">     46734  </td><td style=\"text-align: right;\">        38703.4</td><td style=\"text-align: right;\">        41044.5</td><td style=\"text-align: right;\">       41454.2</td><td style=\"text-align: right;\">       37635.5</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">     0          </td><td style=\"text-align: right;\">     0          </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00004</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.25734   </td><td>[2, 2, 2, 2]</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\">0.000352712</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">     45399.3</td><td style=\"text-align: right;\">     44964.2</td><td style=\"text-align: right;\">        39656.4</td><td style=\"text-align: right;\">        38718.5</td><td style=\"text-align: right;\">       39077.7</td><td style=\"text-align: right;\">       39402.5</td><td style=\"text-align: right;\">       0.999998</td><td style=\"text-align: right;\">       0.999999</td><td style=\"text-align: right;\">    0.999996</td><td style=\"text-align: right;\">    0.999997</td><td style=\"text-align: right;\">     2.25195e-06</td><td style=\"text-align: right;\">     2.71487e-06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00000:\n",
      "  date: 2022-03-25_16-00-12\n",
      "  done: false\n",
      "  experiment_id: 4706dda29d2349a793d93a2f472b9a8c\n",
      "  experiment_tag: 0_batch_size=64,dropout_p=0.092176,h_layers=[3, 5, 2],h_total=10,k=0,lr=0.00016409\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 979\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.9783012866973877\n",
      "  time_this_iter_s: 0.08421802520751953\n",
      "  time_total_s: 2.9783012866973877\n",
      "  timestamp: 1648224012\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 39253.98314173389\n",
      "  train_mape: 0.9998508236609247\n",
      "  train_mape_iqr: 0.00010358227859030844\n",
      "  train_mean_l1: 38378.49073751628\n",
      "  train_med-ape: 0.9999583010909148\n",
      "  train_rmse: 44601.38062049611\n",
      "  training_iteration: 5\n",
      "  trial_id: a36cc_00000\n",
      "  valid_l1_iqr: 39577.82135635793\n",
      "  valid_mape: 0.999884156555035\n",
      "  valid_mape_iqr: 8.520455768790125e-05\n",
      "  valid_mean_l1: 39760.529412408294\n",
      "  valid_med-ape: 0.999954384829557\n",
      "  valid_rmse: 45778.29181888994\n",
      "  \n",
      "Result for train_dnn_raytune_cpu_gpu_distributed_a36cc_00001:\n",
      "  date: 2022-03-25_16-00-28\n",
      "  done: true\n",
      "  experiment_id: d4f2748d5eb64d1fb38c2805dac54a7c\n",
      "  hostname: ip-10-123-137-245\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.123.137.245\n",
      "  pid: 4120\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.910597562789917\n",
      "  time_this_iter_s: 0.08659958839416504\n",
      "  time_total_s: 2.910597562789917\n",
      "  timestamp: 1648224028\n",
      "  timesteps_since_restore: 0\n",
      "  train_l1_iqr: 34086.42642111139\n",
      "  train_mape: 1.0937116678521668\n",
      "  train_mape_iqr: 0.4702464571798932\n",
      "  train_mean_l1: 30784.17786825593\n",
      "  train_med-ape: 0.9857531388715323\n",
      "  train_rmse: 37535.99840303563\n",
      "  training_iteration: 5\n",
      "  trial_id: a36cc_00001\n",
      "  valid_l1_iqr: 33372.281352629216\n",
      "  valid_mape: 0.786897619000256\n",
      "  valid_mape_iqr: 0.2976959764607479\n",
      "  valid_mean_l1: 26230.590258540575\n",
      "  valid_med-ape: 0.6487475182900605\n",
      "  valid_rmse: 32300.813796884155\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 1.9/59.9 GiB<br>Using HyperBand: num_stopped=2 total_brackets=2\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=2, Milestone (r)=5, completed=100.0%): {TERMINATED: 2} \n",
       "  Bracket(Max Size (n)=1, Milestone (r)=3, completed=100.0%): {TERMINATED: 3} <br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/35.31 GiB heap, 0.0/17.65 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/calvin_chan/data/output/checkpoint/testing/train_dnn_raytune_cpu_gpu_distributed_2022-03-25_16-00-08<br>Number of trials: 5/5 (5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                       </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_p</th><th>h_layers    </th><th style=\"text-align: right;\">  h_total</th><th style=\"text-align: right;\">  k</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_rmse</th><th style=\"text-align: right;\">  valid_rmse</th><th style=\"text-align: right;\">  train_mean_l1</th><th style=\"text-align: right;\">  valid_mean_l1</th><th style=\"text-align: right;\">  train_l1_iqr</th><th style=\"text-align: right;\">  valid_l1_iqr</th><th style=\"text-align: right;\">  train_med-ape</th><th style=\"text-align: right;\">  valid_med-ape</th><th style=\"text-align: right;\">  train_mape</th><th style=\"text-align: right;\">  valid_mape</th><th style=\"text-align: right;\">  train_mape_iqr</th><th style=\"text-align: right;\">  valid_mape_iqr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.0921763 </td><td>[3, 5, 2]   </td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0.000164085</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">     44601.4</td><td style=\"text-align: right;\">     45778.3</td><td style=\"text-align: right;\">        38378.5</td><td style=\"text-align: right;\">        39760.5</td><td style=\"text-align: right;\">       39254  </td><td style=\"text-align: right;\">       39577.8</td><td style=\"text-align: right;\">       0.999958</td><td style=\"text-align: right;\">       0.999954</td><td style=\"text-align: right;\">    0.999851</td><td style=\"text-align: right;\">    0.999884</td><td style=\"text-align: right;\">     0.000103582</td><td style=\"text-align: right;\">     8.52046e-05</td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.363724  </td><td>[2, 2, 4]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">0.0988601  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">     37536  </td><td style=\"text-align: right;\">     32300.8</td><td style=\"text-align: right;\">        30784.2</td><td style=\"text-align: right;\">        26230.6</td><td style=\"text-align: right;\">       34086.4</td><td style=\"text-align: right;\">       33372.3</td><td style=\"text-align: right;\">       0.985753</td><td style=\"text-align: right;\">       0.648748</td><td style=\"text-align: right;\">    1.09371 </td><td style=\"text-align: right;\">    0.786898</td><td style=\"text-align: right;\">     0.470246   </td><td style=\"text-align: right;\">     0.297696   </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.586927  </td><td>[4, 2, 2, 2]</td><td style=\"text-align: right;\">       10</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">0.00569188 </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">     46263.6</td><td style=\"text-align: right;\">     45520.8</td><td style=\"text-align: right;\">        40618.2</td><td style=\"text-align: right;\">        39166.1</td><td style=\"text-align: right;\">       37647.5</td><td style=\"text-align: right;\">       41511  </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">     0          </td><td style=\"text-align: right;\">     0          </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.00683811</td><td>[2, 4, 2]   </td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">0.0185841  </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">     44938  </td><td style=\"text-align: right;\">     46734  </td><td style=\"text-align: right;\">        38703.4</td><td style=\"text-align: right;\">        41044.5</td><td style=\"text-align: right;\">       41454.2</td><td style=\"text-align: right;\">       37635.5</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">    1       </td><td style=\"text-align: right;\">     0          </td><td style=\"text-align: right;\">     0          </td></tr>\n",
       "<tr><td>train_dnn_raytune_cpu_gpu_distributed_a36cc_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.25734   </td><td>[2, 2, 2, 2]</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\">0.000352712</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">     45399.3</td><td style=\"text-align: right;\">     44964.2</td><td style=\"text-align: right;\">        39656.4</td><td style=\"text-align: right;\">        38718.5</td><td style=\"text-align: right;\">       39077.7</td><td style=\"text-align: right;\">       39402.5</td><td style=\"text-align: right;\">       0.999998</td><td style=\"text-align: right;\">       0.999999</td><td style=\"text-align: right;\">    0.999996</td><td style=\"text-align: right;\">    0.999997</td><td style=\"text-align: right;\">     2.25195e-06</td><td style=\"text-align: right;\">     2.71487e-06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 16:00:29,077\tINFO tune.py:561 -- Total run time: 20.60 seconds (20.45 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 23.02700185775757s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "result = tune.run(\n",
    "    tune.with_parameters(train_dnn_raytune_cpu_gpu_distributed, \n",
    "                         num_in_feat   = N_FEATURE,\n",
    "                         num_epochs    = num_epochs, \n",
    "                         train_dataset = dataset_train_kfold, \n",
    "                         valid_dataset = dataset_valid_kfold,\n",
    "                         train_metric_samples = round(len(dataset_train_kfold[0])/10),\n",
    "                         ),\n",
    "    config = config,\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    num_samples = num_hp_search_samples,\n",
    "    local_dir = chkpt_dir,\n",
    "    progress_reporter = reporter,\n",
    "    scheduler = scheduler,\n",
    "    search_alg = searchopt,\n",
    ")\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Time elapsed: {t1-t0}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>h_total</th>\n",
       "      <th>h_layers</th>\n",
       "      <th>dropout_p</th>\n",
       "      <th>lr</th>\n",
       "      <th>valid_med-ape</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a36cc_00000</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[3, 5, 2]</td>\n",
       "      <td>0.092176</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.999954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a36cc_00001</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>[2, 2, 4]</td>\n",
       "      <td>0.363724</td>\n",
       "      <td>0.098860</td>\n",
       "      <td>0.648748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a36cc_00002</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>[4, 2, 2, 2]</td>\n",
       "      <td>0.586927</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a36cc_00003</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>[2, 4, 2]</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.018584</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a36cc_00004</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[2, 2, 2, 2]</td>\n",
       "      <td>0.257340</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             k  h_total      h_layers  dropout_p        lr  valid_med-ape\n",
       "trial_id                                                                 \n",
       "a36cc_00000  0       10     [3, 5, 2]   0.092176  0.000164       0.999954\n",
       "a36cc_00001  1        8     [2, 2, 4]   0.363724  0.098860       0.648748\n",
       "a36cc_00002  2       10  [4, 2, 2, 2]   0.586927  0.005692       1.000000\n",
       "a36cc_00003  3        8     [2, 4, 2]   0.006838  0.018584       1.000000\n",
       "a36cc_00004  4        8  [2, 2, 2, 2]   0.257340  0.000353       0.999999"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial = result.get_best_trial(\"valid_med-ape\", \"min\", \"last\")\n",
    "\n",
    "all_trials = result.results_df\n",
    "all_trials.columns = all_trials.columns.str.replace('config.', '', regex=False).tolist()\n",
    "all_trials[['k','h_total','h_layers','dropout_p','lr','valid_med-ape']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 0.0988600955127942, 'dropout_p': 0.3637244172903719, 'k': 1, 'batch_size': 64, 'h_total': 8, 'h_layers': [2, 2, 4]}\n",
      "Best trial final validation loss: 0.6487475182900605\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"valid_med-ape\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling (No Ray Tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] train_rmse: 44656.154, valid_rmse: 40081.069, train_mape: 1.013, valid_mape: 0.810, train_l1_iqr: 38822.949, valid_l1_iqr: 37998.633, \n",
      "[Epoch: 2] train_rmse: 42523.016, valid_rmse: 39647.244, train_mape: 1.131, valid_mape: 0.793, train_l1_iqr: 38067.950, valid_l1_iqr: 38640.221, \n",
      "[Epoch: 3] train_rmse: 41925.223, valid_rmse: 38268.487, train_mape: 1.123, valid_mape: 0.785, train_l1_iqr: 36779.380, valid_l1_iqr: 38560.708, \n",
      "[Epoch: 4] train_rmse: 41800.049, valid_rmse: 39570.515, train_mape: 1.104, valid_mape: 0.787, train_l1_iqr: 37233.037, valid_l1_iqr: 38687.136, \n",
      "[Epoch: 5] train_rmse: 42089.798, valid_rmse: 39741.708, train_mape: 1.107, valid_mape: 0.789, train_l1_iqr: 37493.652, valid_l1_iqr: 38367.757, \n",
      "Time elapsed: 0.46985721588134766s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "layers = [4,3,2]\n",
    "model = dnn(N_FEATURE,layers,dropout_p=0.5).to(device)\n",
    "model.apply(initialize_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n",
    "criterion = nn.MSELoss()\n",
    "metric_dict = {'rmse': lambda y_est,y: torch.sqrt(nn.MSELoss(reduction=\"mean\")(y_est,y)), \n",
    "               'mape': lambda y_est,y: torch.mean((y-y_est).abs()/y.abs()),\n",
    "               'l1_iqr': lambda y_est,y: compute_iqr(nn.L1Loss(reduction=\"none\")(y_est,y))}\n",
    "\n",
    "\n",
    "training_results = train_dnn(model=model, \n",
    "                             train_dataset=dataset_model, \n",
    "                             valid_dataset=dataset_test, \n",
    "                             criterion=criterion,\n",
    "                             optimizer=optimizer,\n",
    "                             metric_dict=metric_dict,\n",
    "                             epochs=num_epochs, \n",
    "                             batch_size=64)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Time elapsed: {t1-t0}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(see: https://skorch.readthedocs.io/en/stable/user/neuralnet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from skorch import NeuralNetRegressor, NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_architecture = [2, 3, 3]\n",
    "dnn_dropout_p = 0.2\n",
    "dnn_act_fn = torch.relu\n",
    "\n",
    "dnn_lr = 1e-4\n",
    "dnn_criterion = nn.MSELoss\n",
    "dnn_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_net = NeuralNet(\n",
    "    module = dnn,\n",
    "    module__in_feat = N_FEATURE,\n",
    "    module__layers = dnn_architecture,\n",
    "    module__dropout_p = dnn_dropout_p,\n",
    "    module__act_fn = dnn_act_fn,\n",
    "    criterion = dnn_criterion,\n",
    "    lr = dnn_lr,\n",
    "    batch_size = dnn_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch           train_loss       valid_loss     dur\n",
      "-------  -------------------  ---------------  ------\n",
      "      1  \u001b[36m33241405015355.0195\u001b[0m  \u001b[32m2022710428.4325\u001b[0m  0.0783\n",
      "      2  \u001b[36m2107227932.1366\u001b[0m  2022710428.4325  0.0717\n",
      "      3  2107227932.1366  2022710428.4325  0.0713\n",
      "      4  2107227932.1366  2022710428.4325  0.0705\n",
      "      5  2107227932.1366  2022710428.4325  0.0724\n",
      "      6  2107227932.1366  2022710428.4325  0.0711\n",
      "      7  2107227932.1366  2022710428.4325  0.0699\n",
      "      8  2107227932.1366  2022710428.4325  0.0815\n",
      "      9  2107227932.1366  2022710428.4325  0.0698\n",
      "     10  2107227932.1366  2022710428.4325  0.0732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.net.NeuralNet'>[initialized](\n",
       "  module_=dnn(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=4, out_features=2, bias=True)\n",
       "      (1): Linear(in_features=2, out_features=3, bias=True)\n",
       "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=3, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_net.fit(pd.concat(x_model).to_numpy(), pd.concat(y_model).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  2107227932.1366  2022710428.4325  0.0784\n",
      "     12  2107227932.1366  2022710428.4325  0.1142\n",
      "     13  2107227932.1366  2022710428.4325  0.1137\n",
      "     14  2107227932.1366  2022710428.4325  0.1146\n",
      "     15  2107227932.1366  2022710428.4325  0.1230\n",
      "     16  2107227932.1366  2022710428.4325  0.1223\n",
      "     17  2107227932.1366  2022710428.4325  0.1218\n",
      "     18  2107227932.1366  2022710428.4325  0.1210\n",
      "     19  2107227932.1366  2022710428.4325  0.1224\n",
      "     20  2107227932.1366  2022710428.4325  0.1248\n",
      "     21  2107227932.1366  2022710428.4325  0.0931\n",
      "     22  2107227932.1366  2022710428.4325  0.0742\n",
      "     23  2107227932.1366  2022710428.4325  0.0889\n",
      "     24  2107227932.1366  2022710428.4325  0.1168\n",
      "     25  2107227932.1366  2022710428.4325  0.0766\n",
      "     26  2107227932.1366  2022710428.4325  0.0748\n",
      "     27  2107227932.1366  2022710428.4325  0.1148\n",
      "     28  2107227932.1366  2022710428.4325  0.0749\n",
      "     29  2107227932.1366  2022710428.4325  0.0772\n",
      "     30  2107227932.1366  2022710428.4325  0.0800\n",
      "     31  2107227932.1366  2022710428.4325  0.0759\n",
      "     32  2107227932.1366  2022710428.4325  0.1163\n",
      "     33  2107227932.1366  2022710428.4325  0.1159\n",
      "     34  2107227932.1366  2022710428.4325  0.1138\n",
      "     35  2107227932.1366  2022710428.4325  0.1156\n",
      "     36  2107227932.1366  2022710428.4325  0.1158\n",
      "     37  2107227932.1366  2022710428.4325  0.1104\n",
      "     38  2107227932.1366  2022710428.4325  0.0892\n",
      "     39  2107227932.1366  2022710428.4325  0.0952\n",
      "     40  2107227932.1366  2022710428.4325  0.1130\n",
      "     41  2107227932.1366  2022710428.4325  0.1173\n",
      "     42  2107227932.1366  2022710428.4325  0.1183\n",
      "     43  2107227932.1366  2022710428.4325  0.1189\n",
      "     44  2107227932.1366  2022710428.4325  0.1212\n",
      "     45  2107227932.1366  2022710428.4325  0.1191\n",
      "     46  2107227932.1366  2022710428.4325  0.0901\n",
      "     47  2107227932.1366  2022710428.4325  0.1199\n",
      "     48  2107227932.1366  2022710428.4325  0.1136\n",
      "     49  2107227932.1366  2022710428.4325  0.1142\n",
      "     50  2107227932.1366  2022710428.4325  0.1144\n",
      "     51  2107227932.1366  2022710428.4325  0.1008\n",
      "     52  2107227932.1366  2022710428.4325  0.0731\n",
      "     53  2107227932.1366  2022710428.4325  0.0749\n",
      "     54  2107227932.1366  2022710428.4325  0.0717\n",
      "     55  2107227932.1366  2022710428.4325  0.0731\n",
      "     56  2107227932.1366  2022710428.4325  0.0713\n",
      "     57  2107227932.1366  2022710428.4325  0.0752\n",
      "     58  2107227932.1366  2022710428.4325  0.0973\n",
      "     59  2107227932.1366  2022710428.4325  0.0731\n",
      "     60  2107227932.1366  2022710428.4325  0.0724\n",
      "     61  2107227932.1366  2022710428.4325  0.0726\n",
      "     62  2107227932.1366  2022710428.4325  0.0737\n",
      "     63  2107227932.1366  2022710428.4325  0.0728\n",
      "     64  2107227932.1366  2022710428.4325  0.0903\n",
      "     65  2107227932.1366  2022710428.4325  0.0766\n",
      "     66  2107227932.1366  2022710428.4325  0.0756\n",
      "     67  2107227932.1366  2022710428.4325  0.0746\n",
      "     68  2107227932.1366  2022710428.4325  0.0813\n",
      "     69  2107227932.1366  2022710428.4325  0.1185\n",
      "     70  2107227932.1366  2022710428.4325  0.1148\n",
      "     71  2107227932.1366  2022710428.4325  0.1156\n",
      "     72  2107227932.1366  2022710428.4325  0.1157\n",
      "     73  2107227932.1366  2022710428.4325  0.1169\n",
      "     74  2107227932.1366  2022710428.4325  0.1156\n",
      "     75  2107227932.1366  2022710428.4325  0.1302\n",
      "     76  2107227932.1366  2022710428.4325  0.0766\n",
      "     77  2107227932.1366  2022710428.4325  0.1172\n",
      "     78  2107227932.1366  2022710428.4325  0.1210\n",
      "     79  2107227932.1366  2022710428.4325  0.1158\n",
      "     80  2107227932.1366  2022710428.4325  0.1151\n",
      "     81  2107227932.1366  2022710428.4325  0.0908\n",
      "     82  2107227932.1366  2022710428.4325  0.1161\n",
      "     83  2107227932.1366  2022710428.4325  0.1173\n",
      "     84  2107227932.1366  2022710428.4325  0.0769\n",
      "     85  2107227932.1366  2022710428.4325  0.0785\n",
      "     86  2107227932.1366  2022710428.4325  0.0799\n",
      "     87  2107227932.1366  2022710428.4325  0.0724\n",
      "     88  2107227932.1366  2022710428.4325  0.0723\n",
      "     89  2107227932.1366  2022710428.4325  0.0726\n",
      "     90  2107227932.1366  2022710428.4325  0.0714\n",
      "     91  2107227932.1366  2022710428.4325  0.0720\n",
      "     92  2107227932.1366  2022710428.4325  0.0746\n",
      "     93  2107227932.1366  2022710428.4325  0.0730\n",
      "     94  2107227932.1366  2022710428.4325  0.0737\n",
      "     95  2107227932.1366  2022710428.4325  0.0735\n",
      "     96  2107227932.1366  2022710428.4325  0.0728\n",
      "     97  2107227932.1366  2022710428.4325  0.0790\n",
      "     98  2107227932.1366  2022710428.4325  0.0984\n",
      "     99  2107227932.1366  2022710428.4325  0.0799\n",
      "    100  2107227932.1366  2022710428.4325  0.0763\n",
      "    101  2107227932.1366  2022710428.4325  0.0772\n",
      "    102  2107227932.1366  2022710428.4325  0.0976\n",
      "    103  2107227932.1366  2022710428.4325  0.1053\n",
      "    104  2107227932.1366  2022710428.4325  0.0802\n",
      "    105  2107227932.1366  2022710428.4325  0.0770\n",
      "    106  2107227932.1366  2022710428.4325  0.0745\n",
      "    107  2107227932.1366  2022710428.4325  0.0733\n",
      "    108  2107227932.1366  2022710428.4325  0.0803\n",
      "    109  2107227932.1366  2022710428.4325  0.0771\n",
      "    110  2107227932.1366  2022710428.4325  0.0755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.net.NeuralNet'>[initialized](\n",
       "  module_=dnn(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=4, out_features=2, bias=True)\n",
       "      (1): Linear(in_features=2, out_features=3, bias=True)\n",
       "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=3, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_net.fit_loop(pd.concat(x_model).to_numpy(), pd.concat(y_model).to_numpy(), epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p39]",
   "language": "python",
   "name": "conda-env-pytorch_p39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
